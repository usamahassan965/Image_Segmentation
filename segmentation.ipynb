{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset"
      ],
      "metadata": {
        "id": "H2Cb7gAcAzmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "def download_and_unzip_gdrive(gdrive_url, download_path, extract_path):\n",
        "    # Get the file ID from the Google Drive URL\n",
        "    file_id = gdrive_url.split(\"/\")[-2]\n",
        "\n",
        "    # Download the file\n",
        "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", download_path, quiet=False)\n",
        "\n",
        "    # Check if the downloaded file is a zip archive\n",
        "    if download_path.endswith('.zip'):\n",
        "        # Extract the contents of the zip file to the specified extract path\n",
        "        with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "    else:\n",
        "        print(\"The downloaded file is not a zip archive.\")\n",
        "\n",
        "# Usage example:\n",
        "gdrive_url = \"https://drive.google.com/file/d/1XVhkMMXKwigQrEPS1rKHbMAH2rKEQdTd/view?usp=drive_link\"\n",
        "download_path = \"/content/downloaded_file.zip\"  # Change to the desired download path in your Colab environment\n",
        "extract_path = \"/content/dataset\"  # Change to the desired extraction path\n",
        "\n",
        "download_and_unzip_gdrive(gdrive_url, download_path, extract_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "iEvntUm3u4Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for data load\n",
        "import os\n",
        "\n",
        "# for reading and processing images\n",
        "import imageio\n",
        "from PIL import Image\n",
        "\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "# for visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np # for using np arrays\n",
        "from numpy import asarray\n",
        "\n",
        "# for bulding and running deep learning model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T20:36:49.900338Z",
          "iopub.execute_input": "2023-10-11T20:36:49.900586Z",
          "iopub.status.idle": "2023-10-11T20:36:56.216734Z",
          "shell.execute_reply.started": "2023-10-11T20:36:49.900558Z",
          "shell.execute_reply": "2023-10-11T20:36:56.216006Z"
        },
        "trusted": true,
        "id": "pNykUsfhtzlK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. UNDERSTAND THE DATA"
      ],
      "metadata": {
        "id": "JAkapu-gtzlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here , you will make a python function which will take paths of images,masks as arguments\n",
        "# and return 2 ordered lists for quarter length of image filepaths and mask filepaths respectively.\n",
        "\n",
        "# Hint : 1-  you may use os package for files listing.\n",
        "# Hint : 2 - you may use sort function for ordering lists"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T20:36:56.558405Z",
          "iopub.execute_input": "2023-10-11T20:36:56.558950Z",
          "iopub.status.idle": "2023-10-11T20:36:56.566010Z",
          "shell.execute_reply.started": "2023-10-11T20:36:56.558915Z",
          "shell.execute_reply": "2023-10-11T20:36:56.563100Z"
        },
        "trusted": true,
        "id": "pUnZLY3QtzlO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = 'Paste the image folder path here'   ## TODO\n",
        "path2 = 'Paste the mask folder path here'    ## TODO\n",
        "img, mask =                   ### TODO: Call the above function here to load file paths for images and masks\n",
        "\n",
        "\n",
        "img_view  = imageio.imread(path1 +'/'+ 'Img_10.jpg')\n",
        "mask_view = imageio.imread(path2 +'/'+ 'Img_10.jpg')\n",
        "\n",
        "print(img_view.shape)\n",
        "print(mask_view.shape)\n",
        "fig, arr = plt.subplots(1, 2, figsize=(15, 15))\n",
        "arr[0].imshow(img_view)\n",
        "arr[0].set_title('Image ' + 'Img_10.jpg')\n",
        "arr[1].imshow(mask_view)\n",
        "arr[1].set_title('Masked Image '+ 'Img_10.jpg')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T20:37:02.686608Z",
          "iopub.execute_input": "2023-10-11T20:37:02.687327Z",
          "iopub.status.idle": "2023-10-11T20:37:03.723587Z",
          "shell.execute_reply.started": "2023-10-11T20:37:02.687294Z",
          "shell.execute_reply": "2023-10-11T20:37:03.722983Z"
        },
        "trusted": true,
        "id": "CU6qHFgGtzlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PreprocessData(img, mask, target_shape_img, target_shape_mask, path1, path2):\n",
        "    \"\"\"\n",
        "    Processes the images and mask present in the shared list and path\n",
        "    Returns a NumPy dataset with images as 3-D arrays of desired size\n",
        "    Please note the masks in this dataset have only one channel\n",
        "    \"\"\"\n",
        "    # Pull the relevant dimensions for image and mask\n",
        "    m =                      # TODO: Assigned number of images to m variable here\n",
        "    i_h,i_w,i_c =           # ToDO:  pull height, width, and channels of image Hint: target_shape_img\n",
        "    m_h,m_w,m_c =           # ToDO:  pull height, width, and channels of mask\n",
        "\n",
        "    # Define X and Y as number of images along with shape of one image\n",
        "    X = np.zeros((m,i_h,i_w,i_c), dtype=np.float32)\n",
        "    y = np.zeros((m,m_h,m_w,m_c), dtype=np.int32)\n",
        "\n",
        "    # Resize images and masks\n",
        "    for file in tqdm(img):\n",
        "        # convert image into an array of desired shape (3 channels)\n",
        "        index = img.index(file)\n",
        "        path = os.path.join(path1, file)\n",
        "        single_img = Image.open(path).convert('RGB')\n",
        "        single_img = single_img.resize((i_h,i_w))\n",
        "        single_img = np.reshape(single_img,(i_h,i_w,i_c))\n",
        "        single_img = single_img/255.\n",
        "        X[index] = single_img\n",
        "\n",
        "        # convert mask into an array of desired shape (1 channel)\n",
        "\n",
        "        single_mask_ind = mask[index]\n",
        "        path = os.path.join(path2, single_mask_ind)\n",
        "        single_mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        single_mask = cv2.resize(single_mask, dsize=(m_h, m_w), interpolation=cv2.INTER_NEAREST)\n",
        "        single_mask = asarray(single_mask)\n",
        "        single_mask = single_mask[..., tf.newaxis]\n",
        "        single_mask = np.reshape(single_mask,(m_h,m_w,m_c))\n",
        "        single_mask = single_mask/255\n",
        "        single_mask = single_mask.astype(int)\n",
        "        y[index] = single_mask\n",
        "    return X, y"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T20:37:08.127300Z",
          "iopub.execute_input": "2023-10-11T20:37:08.127581Z",
          "iopub.status.idle": "2023-10-11T20:37:08.136769Z",
          "shell.execute_reply.started": "2023-10-11T20:37:08.127551Z",
          "shell.execute_reply": "2023-10-11T20:37:08.135964Z"
        },
        "trusted": true,
        "id": "6jWMPRL9tzlS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the desired shape\n",
        "target_shape_img = [128, 128, 3]\n",
        "target_shape_mask = [128, 128, 1]\n",
        "\n",
        "# Process data using apt helper function\n",
        "\n",
        "X, y = PreprocessData(img, mask, target_shape_img, target_shape_mask, path1, path2)\n",
        "\n",
        "# QC the shape of output and classes in output dataset\n",
        "print(\"X Shape:\", X.shape)\n",
        "print(\"Y shape:\", y.shape)\n",
        "# There are 2 classes\n",
        "print(np.unique(y))\n",
        "\n",
        "# Visualize the output\n",
        "image_index = 0\n",
        "fig, arr = plt.subplots(1, 2, figsize=(15, 15))\n",
        "arr[0].imshow(X[image_index])\n",
        "arr[0].set_title('Processed Image')\n",
        "arr[1].imshow(y[image_index,:,:,0])\n",
        "arr[1].set_title('Processed Masked Image ')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T20:37:12.643054Z",
          "iopub.execute_input": "2023-10-11T20:37:12.643516Z",
          "iopub.status.idle": "2023-10-11T20:39:37.338973Z",
          "shell.execute_reply.started": "2023-10-11T20:37:12.643477Z",
          "shell.execute_reply": "2023-10-11T20:39:37.338264Z"
        },
        "trusted": true,
        "id": "tnFIaNKytzlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. UNET MODELING"
      ],
      "metadata": {
        "id": "HCSBsKVwtzlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def EncoderMiniBlock(inputs, n_filters=32, dropout_prob=0.3, max_pooling=True):\n",
        "    \"\"\"\n",
        "    This block uses multiple convolution layers, max pool, relu activation to create an architecture for learning.\n",
        "    Dropout can be added for regularization to prevent overfitting.\n",
        "    The block returns the activation values for next layer along with a skip connection which will be used in the decoder\n",
        "    \"\"\"\n",
        "    # Add 2 Conv Layers with relu activation and HeNormal initialization using TensorFlow\n",
        "    # Proper initialization prevents from the problem of exploding and vanishing gradients\n",
        "    # 'Same' padding will pad the input to conv layer such that the output has the same height and width (hence, is not reduced in size)\n",
        "    conv = Conv2D(n_filters,\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='HeNormal')(inputs)\n",
        "    conv = Conv2D(n_filters,\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='HeNormal')(conv)\n",
        "\n",
        "    # Batch Normalization will normalize the output of the last layer based on the batch's mean and standard deviation\n",
        "    conv = BatchNormalization()(conv, training=False)\n",
        "\n",
        "    # In case of overfitting, dropout will regularize the loss and gradient computation to shrink the influence of weights on output\n",
        "    if dropout_prob > 0:\n",
        "        conv = tf.keras.layers.Dropout(dropout_prob)(conv)\n",
        "\n",
        "    # Pooling reduces the size of the image while keeping the number of channels same\n",
        "    # Pooling has been kept as optional as the last encoder layer does not use pooling (hence, makes the encoder block flexible to use)\n",
        "    # Below, Max pooling considers the maximum of the input slice for output computation and uses stride of 2 to traverse across input image\n",
        "    if max_pooling:\n",
        "        next_layer = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv)\n",
        "    else:\n",
        "        next_layer = conv\n",
        "\n",
        "    # skip connection (without max pooling) will be input to the decoder layer to prevent information loss during transpose convolutions\n",
        "    skip_connection = conv\n",
        "\n",
        "    return next_layer, skip_connection"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T20:39:37.340687Z",
          "iopub.execute_input": "2023-10-11T20:39:37.340959Z",
          "iopub.status.idle": "2023-10-11T20:39:37.349993Z",
          "shell.execute_reply.started": "2023-10-11T20:39:37.340922Z",
          "shell.execute_reply": "2023-10-11T20:39:37.349243Z"
        },
        "trusted": true,
        "id": "f3PqGMMItzlX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DecoderMiniBlock(prev_layer_input, skip_layer_input, n_filters=32):\n",
        "    \"\"\"\n",
        "    Decoder Block first uses transpose convolution to upscale the image to a bigger size and then,\n",
        "    merges the result with skip layer results from encoder block\n",
        "    Adding 2 convolutions with 'same' padding helps further increase the depth of the network for better predictions\n",
        "    The function returns the decoded layer output\n",
        "    \"\"\"\n",
        "    # Start with a transpose convolution layer to first increase the size of the image\n",
        "    up = Conv2DTranspose(\n",
        "                 n_filters,\n",
        "                 (3,3),    # Kernel size\n",
        "                 strides=(2,2),\n",
        "                 padding='same')(prev_layer_input)\n",
        "\n",
        "    # Merge the skip connection from previous block to prevent information loss\n",
        "    merge = concatenate([up, skip_layer_input], axis=3)\n",
        "\n",
        "    # Add 2 Conv Layers with relu activation and HeNormal initialization for further processing\n",
        "    # The parameters for the function are similar to encoder\n",
        "    conv = Conv2D(n_filters,\n",
        "                 3,     # Kernel size\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='HeNormal')(merge)\n",
        "    conv = Conv2D(n_filters,\n",
        "                 3,   # Kernel size\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='HeNormal')(conv)\n",
        "    return conv"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T20:39:37.351124Z",
          "iopub.execute_input": "2023-10-11T20:39:37.351826Z",
          "iopub.status.idle": "2023-10-11T20:39:37.368045Z",
          "shell.execute_reply.started": "2023-10-11T20:39:37.351790Z",
          "shell.execute_reply": "2023-10-11T20:39:37.367301Z"
        },
        "trusted": true,
        "id": "EOZr0PIZtzlZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UNetCompiled(input_size=(128, 128, 3), n_filters=32, n_classes=2):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder includes multiple convolutional mini blocks with different maxpooling, dropout and filter parameters\n",
        "    # Observe that the filters are increasing as we go deeper into the network which will increasse the # channels of the image\n",
        "    cblock1 = EncoderMiniBlock(inputs, n_filters,dropout_prob=0, max_pooling=True)\n",
        "    cblock2 = EncoderMiniBlock(cblock1[0],n_filters*2,dropout_prob=0, max_pooling=True)\n",
        "    cblock3 = EncoderMiniBlock(cblock2[0],n_filters*4,dropout_prob=0, max_pooling=True)\n",
        "    cblock4 =                             #ToDO: Similarly, create another encoder block with filters multiple of 8 and dropout changed to 0.3.\n",
        "    cblock5 =                             #ToDO: Similarly, create another encoder block with filters multiple of 16 and dropout is still 0.3\n",
        "\n",
        "    # Decoder includes multiple mini blocks with decreasing number of filters\n",
        "    # Observe the skip connections from the encoder are given as input to the decoder\n",
        "    # Recall the 2nd output of encoder block was skip connection, hence cblockn[1] is used\n",
        "    ublock6 = DecoderMiniBlock(cblock5[0], cblock4[1],  n_filters * 8)\n",
        "    ublock7 = DecoderMiniBlock(ublock6, cblock3[1],  n_filters * 4)\n",
        "    ublock8 = DecoderMiniBlock(ublock7, cblock2[1],  n_filters * 2)\n",
        "    ublock9 = DecoderMiniBlock(ublock8, cblock1[1],  n_filters)\n",
        "\n",
        "    # Complete the model with 1 3x3 convolution layer (Same as the prev Conv Layers)\n",
        "    # Followed by a 1x1 Conv layer to get the image to the desired size.\n",
        "    # Observe the number of channels will be equal to number of output classes\n",
        "    conv9 = Conv2D(n_filters,\n",
        "                3,\n",
        "                activation='relu',\n",
        "                padding='same',\n",
        "                kernel_initializer='he_normal')(ublock9)\n",
        "\n",
        "    conv10 = Conv2D(n_classes, 1, padding='same')(conv9)\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T20:39:37.370404Z",
          "iopub.execute_input": "2023-10-11T20:39:37.370872Z",
          "iopub.status.idle": "2023-10-11T20:39:37.384411Z",
          "shell.execute_reply.started": "2023-10-11T20:39:37.370837Z",
          "shell.execute_reply": "2023-10-11T20:39:37.383537Z"
        },
        "trusted": true,
        "id": "Nqdehtw7tzla"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use scikit-learn's function to split the dataset\n",
        "# Here, I have used 20% data as test/valid set\n",
        "X_train, X_valid, y_train, y_valid =      ###ToDO:  Use train_test_split from sklearn to split with 80/20 ratio\n",
        "\n",
        "# Call the helper function for defining the layers for the model, given the input image size\n",
        "unet = UNetCompiled(input_size=(128,128,3), n_filters=32, n_classes=3)\n",
        "\n",
        "# Check the summary to better interpret how the output dimensions change in each layer\n",
        "unet.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T20:39:37.385652Z",
          "iopub.execute_input": "2023-10-11T20:39:37.386106Z",
          "iopub.status.idle": "2023-10-11T20:39:41.040155Z",
          "shell.execute_reply.started": "2023-10-11T20:39:37.386072Z",
          "shell.execute_reply": "2023-10-11T20:39:41.039426Z"
        },
        "trusted": true,
        "id": "2kcjQET1tzla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are multiple optimizers, loss functions and metrics that can be used to compile multi-class segmentation models\n",
        "# Ideally, try different options to get the best accuracy\n",
        "unet.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Run the model in a mini-batch fashion and compute the progress for each epoch\n",
        "results = unet.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T20:39:41.041415Z",
          "iopub.execute_input": "2023-10-11T20:39:41.041644Z"
        },
        "trusted": true,
        "id": "iVR2u4wptzlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. PREDICTIONS"
      ],
      "metadata": {
        "id": "dldSbXo1tzlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict masks\n",
        "predictions = []\n",
        "for img in tqdm(X_valid):\n",
        "    img = img[np.newaxis, ...]\n",
        "    pred_y = unet.predict(img)\n",
        "    pred_mask = tf.argmax(pred_y[0], axis=-1)\n",
        "    predictions.append(pred_mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T08:00:45.601927Z",
          "iopub.execute_input": "2023-10-11T08:00:45.602173Z",
          "iopub.status.idle": "2023-10-11T08:05:20.567899Z",
          "shell.execute_reply.started": "2023-10-11T08:00:45.602142Z",
          "shell.execute_reply": "2023-10-11T08:05:20.567128Z"
        },
        "trusted": true,
        "id": "A6g8D44Rtzld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rle_encoding(x):\n",
        "    '''\n",
        "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
        "    Returns run length as list\n",
        "    '''\n",
        "    dots = np.where(x.T.flatten()==1)[0] # .T sets Fortran order down-then-right\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b>prev+1): run_lengths.extend((b+1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return run_lengths"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T08:05:20.569251Z",
          "iopub.execute_input": "2023-10-11T08:05:20.569489Z",
          "iopub.status.idle": "2023-10-11T08:05:20.574563Z",
          "shell.execute_reply.started": "2023-10-11T08:05:20.569458Z",
          "shell.execute_reply": "2023-10-11T08:05:20.57389Z"
        },
        "trusted": true,
        "id": "zR0i4eTttzle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample\n",
        "n_imgs = 10\n",
        "fig,axs = plt.subplots(10,2,figsize = (15,20))\n",
        "fig.suptitle('Testing')\n",
        "for i in range(n_imgs):\n",
        "    axs[i,0].set_title('image')\n",
        "    axs[i,0].imshow(X_valid[i])\n",
        "    axs[i,0].axis('off')\n",
        "\n",
        "    axs[i,1].set_title('y_pred')\n",
        "    axs[i,1].imshow(predictions[i])\n",
        "    axs[i,1].axis('off')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-11T08:05:20.575538Z",
          "iopub.execute_input": "2023-10-11T08:05:20.576162Z",
          "iopub.status.idle": "2023-10-11T08:05:21.339167Z",
          "shell.execute_reply.started": "2023-10-11T08:05:20.576127Z",
          "shell.execute_reply": "2023-10-11T08:05:21.338514Z"
        },
        "trusted": true,
        "id": "9J_5hUmjtzle"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}